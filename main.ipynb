{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "segments = []\n",
    "def read_pdf_segments(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            segment = page.extract_text()\n",
    "            segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "read_pdf_segments(\"narayan-kwach.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {\n",
    "        \"book1\": \"KarmaYoga.pdf\",\n",
    "        \"book2\": \"PracticalVedanta.pdf\",\n",
    "        \"book3\": \"godan.pdf\",\n",
    "        \"book4\": \"abridged-autobiography-hindi.pdf\",\n",
    "        \"book5\": \"narayan-kwach.pdf\"\n",
    "}\n",
    "segmented_books = {}\n",
    "for book in books:\n",
    "    segmented_books[book] = read_pdf_segments(books[book])\n",
    "segmented_books.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\"\n",
    "resfin = []\n",
    "theme = \"न्यास\"\n",
    "for segment in segments:\n",
    "  messages = [\n",
    "    {\n",
    "      \"role\": \"user\", \"content\":'''I will provide you with some text and a theme, your job is to identify the language of the provided text and theme, then generate a question based upon the theme in English. \n",
    "                                   Make sure the question you generate is answerable only by the provided text.\n",
    "                                   Please make no assumptions, and answer in English only.\n",
    "                                   In the case where no such question is possible, answer with the word NO only.''',\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\", \"content\":\"Sure, please provide me with the text and the theme.\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"role\": \"user\", \"content\":\"The text is demarkated by triple backticks:```होरी एक गरीब किसान था, जो मुश्किल से गुजारा कर पा रहा था। अपनी कठिनाइयों के बावजूद, वह एक गाय खरीदने का सपना देखता था, जो गाँव में समृद्धि का प्रतीक थी।```. The theme is demarkated by double backticks:``होरी की गाय खरीदने की इच्छा``.\",\n",
    "    },\n",
    "\n",
    "    {\"role\":\"assistant\",\"content\": \"Why did Hori want a cow?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\":\"user\",\"content\": f'''The text is demarkated by triple backticks:```{segment}```. \n",
    "                                   The theme is demarkated by double backticks:``{theme}``.''',\n",
    "    }\n",
    "  ] \n",
    "\n",
    "  encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  res = decoded[0]\n",
    "  \n",
    "  last_inst_index = res.rfind('[/INST]')\n",
    "  if last_inst_index != -1:\n",
    "      res = res[last_inst_index + len('[/INST]'):]\n",
    "    \n",
    "    \n",
    "  question_mark_index = res.find('?')\n",
    "  if question_mark_index != -1:\n",
    "      res = res[:question_mark_index + 1]  \n",
    "  \n",
    "  if \"NO\" not in res.strip():\n",
    "    resfin.append(res)\n",
    "  if(len(resfin) == 3):\n",
    "    break\n",
    "print(resfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NLLB model and tokenizer\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer_ts = AutoTokenizer.from_pretrained(model_name)\n",
    "model_ts = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text to translate\n",
    "for res in resfin:\n",
    "    text = res\n",
    "\n",
    "    # Tokenize the input text for the source language (English)\n",
    "    tokenizer.src_lang = \"eng_Latn\"\n",
    "    inputs = tokenizer_ts(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Set the target language (Sanskrit) by using the corresponding token ID\n",
    "    target_lang = \"san_Deva\"\n",
    "    forced_bos_token_id = tokenizer_ts.convert_tokens_to_ids(target_lang)\n",
    "\n",
    "    # Generate the translation with a limit on the number of new tokens generated\n",
    "    translated_tokens = model_ts.generate(**inputs, forced_bos_token_id=forced_bos_token_id, max_new_tokens=50)\n",
    "\n",
    "    # Decode the translated tokens to get the final translated text\n",
    "    translated_text = tokenizer_ts.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Print the translated text\n",
    "    print(translated_text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
